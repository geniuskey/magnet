# LLM 설정
# LLM_PROVIDER: anthropic, openai, gemini, litellm, custom 중 선택
LLM_PROVIDER=gemini

# ===== Anthropic =====
ANTHROPIC_API_KEY=sk-ant-xxx
ANTHROPIC_MODEL=claude-sonnet-4-20250514
# ANTHROPIC_API_URL=https://api.anthropic.com  # optional

# ===== OpenAI =====
OPENAI_API_KEY=sk-xxx
OPENAI_MODEL=gpt-5-mini
# OPENAI_API_URL=https://api.openai.com/v1  # optional

# ===== Google Gemini =====
GEMINI_API_KEY=AIzaSyXXX
GEMINI_MODEL=gemini-3-flash-preview
# GEMINI_API_URL=https://generativelanguage.googleapis.com  # optional

# ===== LiteLLM (100+ LLM 통합) =====
# pip install litellm 필요
# 모델명 형식: provider/model (예: openai/gpt-4, anthropic/claude-3, ollama/llama3)
# LITELLM_MODEL=openai/gpt-4
# LITELLM_API_KEY=xxx  # 해당 provider의 API 키 (환경변수로도 설정 가능)
# LITELLM_API_BASE=http://localhost:4000  # LiteLLM Proxy 사용 시
#
# LiteLLM 지원 모델 예시:
# - openai/gpt-4, openai/gpt-3.5-turbo
# - anthropic/claude-3-opus, anthropic/claude-3-sonnet
# - ollama/llama3, ollama/mistral
# - vllm/meta-llama/Llama-2-7b-chat-hf
# - huggingface/bigcode/starcoder
# - bedrock/anthropic.claude-v2

# ===== Custom LLM (OpenAI 호환 API) =====
# Ollama, vLLM, LocalAI, LM Studio 등 OpenAI 호환 API 서버 사용 시
# CUSTOM_API_KEY=xxx  # API 키가 필요한 경우
# CUSTOM_API_URL=http://localhost:11434/v1  # Ollama 예시
# CUSTOM_MODEL=llama3  # 사용할 모델명

# 사내 API
ORG_API_URL=https://intranet.company.com/api/org
CALENDAR_API_URL=https://intranet.company.com/api/calendar
ROOM_API_URL=https://intranet.company.com/api/rooms
API_AUTH_TOKEN=xxx

# 서버 설정
REDIS_URL=redis://localhost:6379
LOG_LEVEL=INFO

# Mock API 사용 여부 (true: Mock 데이터 사용, false: 실제 API 사용)
USE_MOCK_API=true

# CORS 설정 (개발용)
CORS_ORIGINS=http://localhost:5173,http://localhost:3000

# 인증 설정
AUTH_BYPASS=true
SSO_URL=https://sso.company.com
